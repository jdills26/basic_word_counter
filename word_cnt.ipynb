{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_words = \"\"\" Christina Pagel is professor of operational research and director of the Clinical Operational Research Unit at University College London. She is also member of the Independent SAGE group, providing analysis and advice on the covid-19 pandemic.\n",
    "\n",
    "In mid-July, British Prime Minister Boris Johnson promised the country a “significant return to normality” by Christmas. But two weeks after Christmas, that is a far cry from reality, as England enters its third national lockdown in an attempt to contain the rapid spread of covid-19.\n",
    "\n",
    "This week, England admitted the highest number of people with covid-19 to hospitals since the start of the pandemic. Surgeries are being canceled, ambulances are waiting for hours outside hospitals because there are no beds, and health-care staff are exhausted and traumatized. Oxygen infrastructure is already being stressed, as it is in California. Cases keep rising relentlessly, with an overwhelmed National Health Service possible within days.\n",
    "The new variant found in the U.K. has now been identified in the United States, Denmark, France, Spain, Canada and many other countries. What we are going through might be your future. How did we end up in this desperate situation? And how do we get out?\n",
    "\n",
    "In September, cases started rising rapidly in England. On Sept. 21, the government’s scientific advisory committee recommended an immediate short lockdown. Instead, authorities spent six weeks tinkering with regional restrictions of differing severity. We entered our second national lockdown in November, with schools and universities remaining open. Cases, hospital admissions and deaths all fell in the second half of November. Yet by early December, cases were rapidly rising in the southeast corner of England and neighboring London, among the least affected English regions in October.\n",
    "By Dec. 18, the Covid-19 Genomics UK Consortium had identified a new variant of the coronavirus that has since proved to be 40 percent to 70 percent more infectious. On Dec. 22, scientific advisers once again urged immediate restrictions to control its spread, including keeping schools and universities shut in January. But much of England was allowed to mix with up to three households on Christmas Day, and schools for students under 11 were urged to open this week. After schools had been open for just one day, Johnson announced the third lockdown. He has also announced a plan to give nearly 14 million people — people over 70 years old and front-line clinical workers — their first dose of vaccine by mid-February, an exercise that requires us to increase current vaccination rates tenfold.\n",
    "The hope is that these measures will slow the spread of cases, buying us time to vaccinate the most vulnerable. During the first lockdown in March, cases reduced by a factor of 10. Will it work this time?\n",
    "\n",
    "The new lockdown should be enough to slow growth, but given the higher infectiousness of the new variant, it is very possible this will be not be enough to actually drive new cases down. Even if cases level off, we cannot cope with such sustained high numbers of people requiring hospital care. For this lockdown to be effective, England must combine severe restrictions and existing behavioral changes — such as social distancing, avoiding indoor spaces, mask-wearing and frequent hand-washing — with the following measures.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_words2 = \"\"\" \n",
    "Christina Pagel is professor of operational research and director of the Clinical Operational Research Unit at University College London. She is also member of the Independent SAGE group, providing analysis and advice on the covid-19 pandemic.\n",
    "\n",
    "In mid-July, British Prime Minister Boris Johnson promised the country a “significant return to normality” by Christmas. But two weeks after Christmas, that is a far cry from reality, as England enters its third national lockdown in an attempt to contain the rapid spread of covid-19.\n",
    "\n",
    "This week, England admitted the highest number of people with covid-19 to hospitals since the start of the pandemic. Surgeries are being canceled, ambulances are waiting for hours outside hospitals because there are no beds, and health-care staff are exhausted and traumatized. Oxygen infrastructure is already being stressed, as it is in California. Cases keep rising relentlessly, with an overwhelmed National Health Service possible within days.\n",
    "The new variant found in the U.K. has now been identified in the United States, Denmark, France, Spain, Canada and many other countries. What we are going through might be your future. How did we end up in this desperate situation? And how do we get out?\n",
    "\n",
    "In September, cases started rising rapidly in England. On Sept. 21, the government’s scientific advisory committee recommended an immediate short lockdown. Instead, authorities spent six weeks tinkering with regional restrictions of differing severity. We entered our second national lockdown in November, with schools and universities remaining open. Cases, hospital admissions and deaths all fell in the second half of November. Yet by early December, cases were rapidly rising in the southeast corner of England and neighboring London, among the least affected English regions in October.\n",
    "By Dec. 18, the Covid-19 Genomics UK Consortium had identified a new variant of the coronavirus that has since proved to be 40 percent to 70 percent more infectious. On Dec. 22, scientific advisers once again urged immediate restrictions to control its spread, including keeping schools and universities shut in January. But much of England was allowed to mix with up to three \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq(words):\n",
    "    #remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(words)\n",
    "    \n",
    "    # Remove single-character tokens\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    \n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words()]\n",
    "    \n",
    "    # Stemming words - should this be optional?\n",
    "    stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Calculate frequency distribution\n",
    "    fdist = nltk.FreqDist(words)\n",
    "\n",
    "    # Output top 50 words\n",
    "    output_list = []\n",
    "    for word, frequency in fdist.most_common(50):\n",
    "        print(u'{}:{}'.format(word, frequency))\n",
    "        output_list.append((word, frequency))\n",
    "        \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#res = get_freq(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq_chunks(words, chunk_len, min_cnt, stem = False):\n",
    "    #remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(words)\n",
    "    \n",
    "    # Remove single-character tokens\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    \n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words()]\n",
    "\n",
    "    # Stemming words - optional\n",
    "    if stem:\n",
    "        print(\"\\nStemming words...\")\n",
    "        stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    else:\n",
    "        print(\"\\nNOT stemming words...\")\n",
    "        \n",
    "    print(\"\\nLength of words: \", len(words))\n",
    "        \n",
    "    #Chunk the text\n",
    "    chunks = [words[i:i + chunk_len] for i in range(0, len(words), chunk_len)]  \n",
    "    \n",
    "    ck_output_list = []\n",
    "    for ck in chunks:\n",
    "        # Calculate frequency distribution\n",
    "        #print(ck)\n",
    "        print(\"\\nLength of this chunk: \", len(ck))\n",
    "        print(\"Displaying words with a count greater than: \", min_cnt)\n",
    "        #print(\"Displaying top \"+ str(display_cnt) +\" words\")\n",
    "        fdist = nltk.FreqDist(ck)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Output top n words in 250 word chunks\n",
    "        output_list = []\n",
    "        counter = 0\n",
    "        for word, frequency in fdist.most_common(chunk_len):\n",
    "            if frequency > min_cnt:\n",
    "                counter += 1\n",
    "                print(u'{}:{}'.format(word, frequency))\n",
    "                output_list.append((word, frequency))\n",
    "        ck_output_list.append(output_list)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return ck_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOT stemming words...\n",
      "\n",
      "Length of words:  201\n",
      "\n",
      "Length of this chunk:  201\n",
      "Displaying words with a count greater than:  2\n",
      "\n",
      "\n",
      "england:5\n",
      "cases:4\n",
      "covid:4\n",
      "rising:3\n",
      "lockdown:3\n",
      "national:3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = get_freq_chunks(raw_words2, 250, 2, stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming words...\n",
      "\n",
      "Length of words:  6\n",
      "\n",
      "Length of this chunk:  6\n",
      "Displaying words with a count greater than:  0\n",
      "\n",
      "\n",
      "hand:3\n",
      "run:2\n",
      "walk:1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testw = \"\"\"hand handed hands walked run running\"\"\"\n",
    "res = get_freq_chunks(testw, 100, 0, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['og',\n",
       " 'i',\n",
       " 'jeg',\n",
       " 'det',\n",
       " 'at',\n",
       " 'en',\n",
       " 'den',\n",
       " 'til',\n",
       " 'er',\n",
       " 'som',\n",
       " 'på',\n",
       " 'de',\n",
       " 'med',\n",
       " 'han',\n",
       " 'af',\n",
       " 'for',\n",
       " 'ikke',\n",
       " 'der',\n",
       " 'var',\n",
       " 'mig',\n",
       " 'sig',\n",
       " 'men',\n",
       " 'et',\n",
       " 'har',\n",
       " 'om',\n",
       " 'vi',\n",
       " 'min',\n",
       " 'havde',\n",
       " 'ham',\n",
       " 'hun',\n",
       " 'nu',\n",
       " 'over',\n",
       " 'da',\n",
       " 'fra',\n",
       " 'du',\n",
       " 'ud',\n",
       " 'sin',\n",
       " 'dem',\n",
       " 'os',\n",
       " 'op',\n",
       " 'man',\n",
       " 'hans',\n",
       " 'hvor',\n",
       " 'eller',\n",
       " 'hvad',\n",
       " 'skal',\n",
       " 'selv',\n",
       " 'her',\n",
       " 'alle',\n",
       " 'vil',\n",
       " 'blev',\n",
       " 'kunne',\n",
       " 'ind',\n",
       " 'når',\n",
       " 'være',\n",
       " 'dog',\n",
       " 'noget',\n",
       " 'ville',\n",
       " 'jo',\n",
       " 'deres',\n",
       " 'efter',\n",
       " 'ned',\n",
       " 'skulle',\n",
       " 'denne',\n",
       " 'end',\n",
       " 'dette',\n",
       " 'mit',\n",
       " 'også',\n",
       " 'under',\n",
       " 'have',\n",
       " 'dig',\n",
       " 'anden',\n",
       " 'hende',\n",
       " 'mine',\n",
       " 'alt',\n",
       " 'meget',\n",
       " 'sit',\n",
       " 'sine',\n",
       " 'vor',\n",
       " 'mod',\n",
       " 'disse',\n",
       " 'hvis',\n",
       " 'din',\n",
       " 'nogle',\n",
       " 'hos',\n",
       " 'blive',\n",
       " 'mange',\n",
       " 'ad',\n",
       " 'bliver',\n",
       " 'hendes',\n",
       " 'været',\n",
       " 'thi',\n",
       " 'jer',\n",
       " 'sådan',\n",
       " 'de',\n",
       " 'en',\n",
       " 'van',\n",
       " 'ik',\n",
       " 'te',\n",
       " 'dat',\n",
       " 'die',\n",
       " 'in',\n",
       " 'een',\n",
       " 'hij',\n",
       " 'het',\n",
       " 'niet',\n",
       " 'zijn',\n",
       " 'is',\n",
       " 'was',\n",
       " 'op',\n",
       " 'aan',\n",
       " 'met',\n",
       " 'als',\n",
       " 'voor',\n",
       " 'had',\n",
       " 'er',\n",
       " 'maar',\n",
       " 'om',\n",
       " 'hem',\n",
       " 'dan',\n",
       " 'zou',\n",
       " 'of',\n",
       " 'wat',\n",
       " 'mijn',\n",
       " 'men',\n",
       " 'dit',\n",
       " 'zo',\n",
       " 'door',\n",
       " 'over',\n",
       " 'ze',\n",
       " 'zich',\n",
       " 'bij',\n",
       " 'ook',\n",
       " 'tot',\n",
       " 'je',\n",
       " 'mij',\n",
       " 'uit',\n",
       " 'der',\n",
       " 'daar',\n",
       " 'haar',\n",
       " 'naar',\n",
       " 'heb',\n",
       " 'hoe',\n",
       " 'heeft',\n",
       " 'hebben',\n",
       " 'deze',\n",
       " 'u',\n",
       " 'want',\n",
       " 'nog',\n",
       " 'zal',\n",
       " 'me',\n",
       " 'zij',\n",
       " 'nu',\n",
       " 'ge',\n",
       " 'geen',\n",
       " 'omdat',\n",
       " 'iets',\n",
       " 'worden',\n",
       " 'toch',\n",
       " 'al',\n",
       " 'waren',\n",
       " 'veel',\n",
       " 'meer',\n",
       " 'doen',\n",
       " 'toen',\n",
       " 'moet',\n",
       " 'ben',\n",
       " 'zonder',\n",
       " 'kan',\n",
       " 'hun',\n",
       " 'dus',\n",
       " 'alles',\n",
       " 'onder',\n",
       " 'ja',\n",
       " 'eens',\n",
       " 'hier',\n",
       " 'wie',\n",
       " 'werd',\n",
       " 'altijd',\n",
       " 'doch',\n",
       " 'wordt',\n",
       " 'wezen',\n",
       " 'kunnen',\n",
       " 'ons',\n",
       " 'zelf',\n",
       " 'tegen',\n",
       " 'na',\n",
       " 'reeds',\n",
       " 'wil',\n",
       " 'kon',\n",
       " 'niets',\n",
       " 'uw',\n",
       " 'iemand',\n",
       " 'geweest',\n",
       " 'andere',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mustn',\n",
       " 'needn',\n",
       " 'shan',\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'olla',\n",
       " 'olen',\n",
       " 'olet',\n",
       " 'on',\n",
       " 'olemme',\n",
       " 'olette',\n",
       " 'ovat',\n",
       " 'ole',\n",
       " 'oli',\n",
       " 'olisi',\n",
       " 'olisit',\n",
       " 'olisin',\n",
       " 'olisimme',\n",
       " 'olisitte',\n",
       " 'olisivat',\n",
       " 'olit',\n",
       " 'olin',\n",
       " 'olimme',\n",
       " 'olitte',\n",
       " 'olivat',\n",
       " 'ollut',\n",
       " 'olleet',\n",
       " 'en',\n",
       " 'et',\n",
       " 'ei',\n",
       " 'emme',\n",
       " 'ette',\n",
       " 'eivät',\n",
       " 'minä',\n",
       " 'minun',\n",
       " 'minut',\n",
       " 'minua',\n",
       " 'minussa',\n",
       " 'minusta',\n",
       " 'minuun',\n",
       " 'minulla',\n",
       " 'minulta',\n",
       " 'minulle',\n",
       " 'sinä',\n",
       " 'sinun',\n",
       " 'sinut',\n",
       " 'sinua',\n",
       " 'sinussa',\n",
       " 'sinusta',\n",
       " 'sinuun',\n",
       " 'sinulla',\n",
       " 'sinulta',\n",
       " 'sinulle',\n",
       " 'hän',\n",
       " 'hänen',\n",
       " 'hänet',\n",
       " 'häntä',\n",
       " 'hänessä',\n",
       " 'hänestä',\n",
       " 'häneen',\n",
       " 'hänellä',\n",
       " 'häneltä',\n",
       " 'hänelle',\n",
       " 'me',\n",
       " 'meidän',\n",
       " 'meidät',\n",
       " 'meitä',\n",
       " 'meissä',\n",
       " 'meistä',\n",
       " 'meihin',\n",
       " 'meillä',\n",
       " 'meiltä',\n",
       " 'meille',\n",
       " 'te',\n",
       " 'teidän',\n",
       " 'teidät',\n",
       " 'teitä',\n",
       " 'teissä',\n",
       " 'teistä',\n",
       " 'teihin',\n",
       " 'teillä',\n",
       " 'teiltä',\n",
       " 'teille',\n",
       " 'he',\n",
       " 'heidän',\n",
       " 'heidät',\n",
       " 'heitä',\n",
       " 'heissä',\n",
       " 'heistä',\n",
       " 'heihin',\n",
       " 'heillä',\n",
       " 'heiltä',\n",
       " 'heille',\n",
       " 'tämä',\n",
       " 'tämän',\n",
       " 'tätä',\n",
       " 'tässä',\n",
       " 'tästä',\n",
       " 'tähän',\n",
       " 'tallä',\n",
       " 'tältä',\n",
       " 'tälle',\n",
       " 'tänä',\n",
       " 'täksi',\n",
       " 'tuo',\n",
       " 'tuon',\n",
       " 'tuotä',\n",
       " 'tuossa',\n",
       " 'tuosta',\n",
       " 'tuohon',\n",
       " 'tuolla',\n",
       " 'tuolta',\n",
       " 'tuolle',\n",
       " 'tuona',\n",
       " 'tuoksi',\n",
       " 'se',\n",
       " 'sen',\n",
       " 'sitä',\n",
       " 'siinä',\n",
       " 'siitä',\n",
       " 'siihen',\n",
       " 'sillä',\n",
       " 'siltä',\n",
       " 'sille',\n",
       " 'sinä',\n",
       " 'siksi',\n",
       " 'nämä',\n",
       " 'näiden',\n",
       " 'näitä',\n",
       " 'näissä',\n",
       " 'näistä',\n",
       " 'näihin',\n",
       " 'näillä',\n",
       " 'näiltä',\n",
       " 'näille',\n",
       " 'näinä',\n",
       " 'näiksi',\n",
       " 'nuo',\n",
       " 'noiden',\n",
       " 'noita',\n",
       " 'noissa',\n",
       " 'noista',\n",
       " 'noihin',\n",
       " 'noilla',\n",
       " 'noilta',\n",
       " 'noille',\n",
       " 'noina',\n",
       " 'noiksi',\n",
       " 'ne',\n",
       " 'niiden',\n",
       " 'niitä',\n",
       " 'niissä',\n",
       " 'niistä',\n",
       " 'niihin',\n",
       " 'niillä',\n",
       " 'niiltä',\n",
       " 'niille',\n",
       " 'niinä',\n",
       " 'niiksi',\n",
       " 'kuka',\n",
       " 'kenen',\n",
       " 'kenet',\n",
       " 'ketä',\n",
       " 'kenessä',\n",
       " 'kenestä',\n",
       " 'keneen',\n",
       " 'kenellä',\n",
       " 'keneltä',\n",
       " 'kenelle',\n",
       " 'kenenä',\n",
       " 'keneksi',\n",
       " 'ketkä',\n",
       " 'keiden',\n",
       " 'ketkä',\n",
       " 'keitä',\n",
       " 'keissä',\n",
       " 'keistä',\n",
       " 'keihin',\n",
       " 'keillä',\n",
       " 'keiltä',\n",
       " 'keille',\n",
       " 'keinä',\n",
       " 'keiksi',\n",
       " 'mikä',\n",
       " 'minkä',\n",
       " 'minkä',\n",
       " 'mitä',\n",
       " 'missä',\n",
       " 'mistä',\n",
       " 'mihin',\n",
       " 'millä',\n",
       " 'miltä',\n",
       " 'mille',\n",
       " 'minä',\n",
       " 'miksi',\n",
       " 'mitkä',\n",
       " 'joka',\n",
       " 'jonka',\n",
       " 'jota',\n",
       " 'jossa',\n",
       " 'josta',\n",
       " 'johon',\n",
       " 'jolla',\n",
       " 'jolta',\n",
       " 'jolle',\n",
       " 'jona',\n",
       " 'joksi',\n",
       " 'jotka',\n",
       " 'joiden',\n",
       " 'joita',\n",
       " 'joissa',\n",
       " 'joista',\n",
       " 'joihin',\n",
       " 'joilla',\n",
       " 'joilta',\n",
       " 'joille',\n",
       " 'joina',\n",
       " 'joiksi',\n",
       " 'että',\n",
       " 'ja',\n",
       " 'jos',\n",
       " 'koska',\n",
       " 'kuin',\n",
       " 'mutta',\n",
       " 'niin',\n",
       " 'sekä',\n",
       " 'sillä',\n",
       " 'tai',\n",
       " 'vaan',\n",
       " 'vai',\n",
       " 'vaikka',\n",
       " 'kanssa',\n",
       " 'mukaan',\n",
       " 'noin',\n",
       " 'poikki',\n",
       " 'yli',\n",
       " 'kun',\n",
       " 'niin',\n",
       " 'nyt',\n",
       " 'itse',\n",
       " 'au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent',\n",
       " 'aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen',\n",
       " 'a',\n",
       " 'ahogy',\n",
       " 'ahol',\n",
       " 'aki',\n",
       " 'akik',\n",
       " 'akkor',\n",
       " 'alatt',\n",
       " 'által',\n",
       " 'általában',\n",
       " 'amely',\n",
       " 'amelyek',\n",
       " 'amelyekben',\n",
       " 'amelyeket',\n",
       " 'amelyet',\n",
       " 'amelynek',\n",
       " 'ami',\n",
       " 'amit',\n",
       " 'amolyan',\n",
       " 'amíg',\n",
       " 'amikor',\n",
       " 'át',\n",
       " 'abban',\n",
       " 'ahhoz',\n",
       " 'annak',\n",
       " 'arra',\n",
       " 'arról',\n",
       " 'az',\n",
       " 'azok',\n",
       " 'azon',\n",
       " 'azt',\n",
       " 'azzal',\n",
       " ...]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
